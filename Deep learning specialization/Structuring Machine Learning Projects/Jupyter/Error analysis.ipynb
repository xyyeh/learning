{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e45ce96e-3317-4602-89d7-3f59376411fc",
   "metadata": {},
   "source": [
    "### Week 2\n",
    "#### Cleaning up incorrectly labeled data\n",
    "1. Apply the same cleaning processes from your **training** set to the **dev** and **test** sets. Dev and test sets should be from the same distribution.\n",
    "2. Consider examples that your algorithm got wrong.\n",
    "3. **Train** and **dev/test** data may now come from slightly different distributions. This is okay as training sets are large in size. Thus, the additional corrections might only form a small fraction of the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd181838-b6c2-48c0-bcfd-1c730d759a17",
   "metadata": {},
   "source": [
    "#### Mismatched training and dev/test set\n",
    "1. Nowadays, you can crawl the web to find tons of pictures as your dataset. However, your final application may be on a mobile phone that has pictures from a different distribution. You can consider several ways to merge the two sets of data.\n",
    "    * Option 1: Given $N$ and $M$ data points where $N >> M$ and $M$ is the dataset we are interested in, shuffle the $N+M$ data randomly and distribute them into the train/dev/test sets. This is a simple approach with one main disadvantage is that the dev set will contain mostly data from $N$, this would bias our metrics towards the less important dataset.\n",
    "    * Option 2: Split $M$ equally into two portions. Combine one portion to form the $N+\\frac{M}{2}$ training set and split the remaining half equally between dev ($\\frac{M}{2}$) and test ($\\frac{M}{2}$) sets\n",
    "2. Now that the training (for example, with a huge chunk of synthetic data) and the dev/test sets do not share the same distribution, we will need good ways to estimate the biases and variances so that we make informed decisions in fine-tuning our models. When the training error is low but the dev error is not, two things might have happened and we need more thorough analysis to isolate one from the other\n",
    "    * The algorithm saw data in the training set but not in the dev set, i.e. variance problem\n",
    "    * The distribution of data in the dev set is different, i.e. distribution mismatch\n",
    "3. To resolve this issue, we use a training-dev set that is carved out from the training set. The training-dev set thus has the same distribution as the training set. So, if the training error is **small** but the training-dev error is **large**, we can conclude that this is a **variance** problem, i.e. the algorithm overfitted to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cf18ee-2309-410c-a819-d3d4f9df0979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
