{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ILQR example\n",
    "1. The example shows how to compute the ilqr solution to a 1 dof actuated pendulum\n",
    "2. At this point we are only penalizing the control inputs and the deviation from the final state in the overall cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete dynamics\n",
    "1. In the following the symbolic dynamics of the pendulum is defined.\n",
    "2. For convenience, lambda functions are used for:\n",
    "    - The discrete dynamics $x_{k+1} = f(u_k, x_k)$\n",
    "    - The linearized system with $A = \\frac{\\partial f}{\\partial x}$ and $B = \\frac{\\partial f}{\\partial u}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy.matrices import Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbolic_dynamics_pendulum():\n",
    "    \"\"\"Symbolic dynamics for a pendulum\n",
    "\n",
    "    Returns:\n",
    "        sympy.Function: f(x.u)\n",
    "        sympy.Function: df/dx\n",
    "        sympy.Function: df/du\n",
    "    \"\"\"\n",
    "    m, g, L, theta, theta_dot, u, dt = sp.symbols('m g L theta theta_dot u dt')\n",
    "\n",
    "    # inputs and states\n",
    "    inputs = Matrix([u])\n",
    "    states = Matrix([theta, theta_dot])\n",
    "\n",
    "    # dynamics for a pendulum of mass m and center of mass L\n",
    "    # ----------------\n",
    "    #        |\\\n",
    "    #        | \\\n",
    "    # \\theta |->\\\n",
    "    #        |  []\n",
    "    f = Matrix([theta_dot, (u-m*g*L*sp.sin(theta))/(m*L*L)])\n",
    "\n",
    "    # discretize the system using euler integration\n",
    "    f_disc = states + f*dt\n",
    "\n",
    "    # first derivatives wrt to (x, u)\n",
    "    f_x = f_disc.jacobian(states) # df/dx\n",
    "    f_u = f_disc.jacobian(inputs) # df/du\n",
    "\n",
    "    # second derivatives wrt to (x, u)\n",
    "    # f_xx = f_x.(states) # d2f/dx2\n",
    "    # f_uu = f_u.jacobian(states) # d2f/du2\n",
    "\n",
    "    # define parameters\n",
    "    parameters = Matrix([m,g,L])\n",
    "\n",
    "    # create lambdas\n",
    "    f_func = sp.lambdify((states, inputs, dt, parameters), f_disc)\n",
    "    f_x_func = sp.lambdify((states, inputs, dt, parameters), f_x)\n",
    "    f_u_func = sp.lambdify((states, inputs, dt, parameters), f_u)\n",
    "    # f_xx_func = sp.lambdify((states, inputs, dt, parameters), f_xx)\n",
    "    # f_uu_func = sp.lambdify((states, inputs, dt, parameters), f_uu)\n",
    "\n",
    "    # return (f_func, f_x_func, f_u_func, f_xx_func, f_uu_func)\n",
    "    return (f_func, f_x_func, f_u_func)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative LQR algorithm\n",
    "1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ilqr:\n",
    "    def __init__(self, init_state, target_state, initial_guess, dt, start_time, end_time, f_discrete, f_x, f_u, Q_k, R_k, Q_T, parameters, n_iterations):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Args:\n",
    "            init_state (ndarray): Initial state\n",
    "            target_state (ndarray): Target state\n",
    "            initial_guess (ndarray): Initial guess for ilqr\n",
    "            dt (double): Sampling time for discrete system\n",
    "            start_time (double): Starting time, defaults to 0 for a single trajectory\n",
    "            end_time (double): Ending time, defaults to final time for a single trajectory\n",
    "            f_discrete (sympy.Matrix): Symbolic representation of the x_{k_+1} = f(x_k, u_k)\n",
    "            f_x (sympy.Matrix): df_dx term of the linearized system\n",
    "            f_u (sympy.Matrix): df_du term of the linearized system\n",
    "            Q_k (ndarray): Weights for states in the running cost\n",
    "            R_k (ndarray): Weights for inputs in the running cost\n",
    "            Q_T (ndarray): Weights for states in the terminal cost\n",
    "            parameters (ndarray): Parameters of the system\n",
    "            n_iterations (double): Maximum interations for ilqr\n",
    "        \"\"\"\n",
    "        # states\n",
    "        self.init_state_ = init_state\n",
    "        self.target_state_ = target_state\n",
    "        self.inputs_ = initial_guess\n",
    "        self.n_states_ = np.shape(init_state)[0] # The dimensions of the state vector\n",
    "        self.n_inputs_ = np.shape(initial_guess)[1] # The dimension of the control vector\n",
    "\n",
    "        # timing\n",
    "        self.dt_ = dt\n",
    "        self.start_time_ = start_time\n",
    "        self.end_time_ = end_time\n",
    "        self.time_span_ = np.arange(start_time, end_time, dt).flatten()\n",
    "        self.n_timesteps_ = np.shape(self.time_span_)[0]\n",
    "\n",
    "        # dynamics\n",
    "        self.f_ = f_discrete\n",
    "        self.f_x_ = f_x\n",
    "        self.f_u_ = f_u\n",
    "\n",
    "        # weighting for loss function, i.e. L = x_T^T Q_T x_T + sum of (x_k^T Q_k x_k + u_k^T R_k u_k)\n",
    "        self.Q_k_ = Q_k # Weight for state vector\n",
    "        self.R_k_ = R_k # Weight for control vector\n",
    "        self.Q_T_ = Q_T # Weight for terminal state\n",
    "        self.parameters_ = parameters\n",
    "\n",
    "        # max iterations to run\n",
    "        self.n_iterations_ = n_iterations\n",
    "\n",
    "        # costs\n",
    "        self.expected_cost_reduction_ = 0\n",
    "        self.expected_cost_reduction_grad_ = 0\n",
    "        self.expected_cost_reduction_hess_ = 0\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\"Rollout of the simulated system given an initial state\n",
    "\n",
    "        Returns:\n",
    "            ndarray: States trajectory from the rollout\n",
    "            ndarray: Inputs trajectory from the rollout\n",
    "        \"\"\"\n",
    "        # we store states and inputs as:\n",
    "        # state = [., x_1, x_2, ..., x_N]\n",
    "        # input =    [u_0, u_1, ..., u_{N-1}]\n",
    "        # the first value in state is understood as self.init_state_\n",
    "        states = np.zeros((self.n_timesteps_+1, self.n_states_)) # including initial state, x_0 to x_N\n",
    "        inputs = np.zeros((self.n_timesteps_, self.n_inputs_)) # u_0 to u_{N-1}\n",
    "        current_state = self.init_state_\n",
    "        next_state = self.f_(current_state, self.inputs_[0, :],\n",
    "                             self.dt_, self.parameters_).flatten()\n",
    "\n",
    "        for i in range(0, self.n_timesteps_): # 0 to N-1\n",
    "            current_input = self.inputs_[i,:] # u_k\n",
    "            next_state = self.f_(current_state, current_input, self.dt_, self.parameters_).flatten() # x_{k+1} = f(x_k, u_k) \n",
    "            # store both u_k and x_{k+1}\n",
    "            states[i+1,:] = next_state\n",
    "            inputs[i,:] = current_input\n",
    "            # update current state\n",
    "            current_state = next_state\n",
    "\n",
    "        # store trajectories\n",
    "        self.states_ = states\n",
    "        self.inputs_ = inputs\n",
    "\n",
    "        return states, inputs\n",
    "\n",
    "    def compute_cost(self, states, inputs):\n",
    "        \"\"\"Computes the cost from all the terms, i.e. dynamics and cost as well as their derivatives:\n",
    "        f_x, f_u, f_xx, f_ux, f_uu, \n",
    "        l_x, l_u, l_xx, l_ux, l_uu\n",
    "\n",
    "        Args:\n",
    "            states (ndarray): State trajectory\n",
    "            inputs (ndarray): Input trajectory\n",
    "\n",
    "        Returns:\n",
    "            double: Total cost, i.e. terminal cost + running cost\n",
    "        \"\"\"\n",
    "        # dynamics first derivatives\n",
    "\n",
    "        # dynamics second derivatives\n",
    "\n",
    "        # cost first derivatives\n",
    "\n",
    "        # cost second derivatives\n",
    "\n",
    "        # accumulate cost to go\n",
    "        total_cost = 0\n",
    "        for i in range(0, self.n_timesteps_):\n",
    "            current_x = states[i,:]\n",
    "            current_u = inputs[i,:].flatten()\n",
    "            current_cost = current_u.T @ self.R_k_ @ current_u\n",
    "            total_cost = total_cost + current_cost\n",
    "        # add terminal cost\n",
    "        terminal_diff = (states[-1,:] - self.target_state_).flatten()\n",
    "        terminal_cost = terminal_diff.T @ self.Q_T_ @ terminal_diff\n",
    "        total_cost = total_cost + terminal_cost\n",
    "\n",
    "        return total_cost\n",
    "\n",
    "    def backward_pass(self):\n",
    "        \"\"\"Backward pass of iLQR\n",
    "\n",
    "        Returns:\n",
    "            ndarray: feedforward gain, k\n",
    "            ndarray: feedback gain, K\n",
    "            double: expected cost reduction\n",
    "        \"\"\"\n",
    "        # starting from the last state\n",
    "        V_xx = self.Q_T_ # since V_N = x_T^T Q_T x_T, V_xx(N) = Q_T_\n",
    "        end_difference = (self.states_[-1, :] - self.target_state_).flatten()\n",
    "        end_difference = end_difference.flatten()\n",
    "        V_x = self.Q_T_ @ end_difference # V_x(N)\n",
    "\n",
    "        # initialize control modifications to be stored\n",
    "        k_trj = np.zeros((self.n_timesteps_, self.n_inputs_)) # (8b)\n",
    "        K_trj = np.zeros((self.n_timesteps_, self.n_inputs_, self.n_states_)) # (8b)\n",
    "\n",
    "        # initialize cost reduction\n",
    "        expected_cost_reduction = 0\n",
    "        expected_cost_reduction_grad = 0\n",
    "        expected_cost_reduction_hess = 0\n",
    "\n",
    "        # looping backwards from N-1 to 1 using initial value of V_{N}\n",
    "        for i in reversed(range(0, self.n_timesteps_)):\n",
    "            # current variables\n",
    "            current_x = self.states_[i,:]\n",
    "            current_u = self.inputs_[i,:]\n",
    "\n",
    "            # updates to partial derivatives of cost function\n",
    "            l_xx = self.Q_k_\n",
    "            l_uu = self.R_k_\n",
    "\n",
    "            # l_ux = np.zeros((self.n_inputs_, self.n_states_))\n",
    "            l_x = self.Q_k_ @ np.zeros(self.n_states_).flatten()\n",
    "            l_u = self.R_k_ @ (current_u).flatten()\n",
    "\n",
    "            # get jacobian of discrete dynamics\n",
    "            f_x = self.f_x_(current_x, current_u, self.dt_, self.parameters_) # V'_x\n",
    "            f_u = self.f_u_(current_x, current_u, self.dt_, self.parameters_) # V'_u\n",
    "    \n",
    "            # all the Q vector/matrices\n",
    "            Q_x = l_x + f_x.T @ V_x # (5a)\n",
    "            Q_u = l_u + f_u.T @ V_x # (5b)\n",
    "            Q_ux = f_u.T @ V_xx @ f_x # (5c)\n",
    "            Q_uu = l_uu + f_u.T @ V_xx @ f_u # (5d)\n",
    "            Q_xx = l_xx + f_x.T @ V_xx @ f_x # (5e)\n",
    "\n",
    "            # compute and store gains\n",
    "            kSingValThreshold = 1e-4\n",
    "            (_,s,_) = np.linalg.svd(Q_uu)\n",
    "            if (np.min(s) < kSingValThreshold):\n",
    "                print(\"Q_uu is non-singular\")\n",
    "            Q_uu_inv = np.linalg.inv(Q_uu) # TODO: this can be singular, try using (9)\n",
    "            k = -Q_uu_inv @ Q_u # (6)\n",
    "            K = -Q_uu_inv @ Q_ux # (6)\n",
    "\n",
    "            k_trj[i,:] = k \n",
    "            K_trj[i,:,:] = K \n",
    "\n",
    "            # update the expected reduction (11a), delta V\n",
    "            # similar to equation of delta J(\\alpha)\n",
    "            current_cost_reduction_grad = -Q_u.T @ k\n",
    "            current_cost_reduction_hess = (0.5 * k.T @ (Q_uu) @ (k))\n",
    "            current_cost_reduction = current_cost_reduction_grad + current_cost_reduction_hess\n",
    "\n",
    "            expected_cost_reduction_grad += current_cost_reduction_grad\n",
    "            expected_cost_reduction_hess += current_cost_reduction_hess\n",
    "            expected_cost_reduction += current_cost_reduction\n",
    "\n",
    "            # update hessian and gradient of value function for the next iteration\n",
    "            V_x = Q_x + K.T @ Q_uu @ k + K.T @ Q_u + Q_ux.T @ k # (11b)\n",
    "            V_xx = Q_xx + K.T @ Q_uu @ K + K.T @ Q_ux + Q_ux.T @ K # (11c)\n",
    "\n",
    "        # store values\n",
    "        self.expected_cost_reduction_grad_ = expected_cost_reduction_grad\n",
    "        self.expected_cost_reduction_hess_ = expected_cost_reduction_hess\n",
    "        self.expected_cost_reduction_ = expected_cost_reduction\n",
    "\n",
    "        # store gains\n",
    "        self.k_feedforward_ = k_trj\n",
    "        self.K_feedback_ = K_trj\n",
    "\n",
    "        return (k_trj, K_trj, expected_cost_reduction)\n",
    "\n",
    "    def forward_pass(self, learning_rate):\n",
    "        \"\"\"Forward pass of iLQR\n",
    "\n",
    "        Args:\n",
    "            learning_rate (double): learning rate (\\alpha)\n",
    "            \n",
    "        Returns:\n",
    "            ndarray: updated states, \\hat x (8a,b,c)\n",
    "            ndarray: updated inputs, \\hat u (12)\n",
    "        \"\"\"\n",
    "        # initialize before integration\n",
    "        states = np.zeros((self.n_timesteps_ + 1, self.n_states_)) # to store updated trajectory\n",
    "        inputs = np.zeros((self.n_timesteps_, self.n_inputs_)) # to store updated inputs\n",
    "        current_state = self.init_state_\n",
    "\n",
    "        # initialize and start integrating going forward for:\n",
    "        # state = [., x_1, x_2, ..., x_N]\n",
    "        # input =    [u_0, u_1, ..., u_{N-1}]\n",
    "        states[1,:] = current_state # (8a), assume that index 0 contains x_0\n",
    "        for i in range(0, self.n_timesteps_):\n",
    "            # use current gains\n",
    "            current_feedforward = learning_rate * self.k_feedforward_[i,:] # (12), \\hat represents the updated variables\n",
    "            current_feedback = self.K_feedback_[i,:,:] @ (current_state - self.states_[i,:]) # (12)\n",
    "            current_input = self.inputs_[i,:] + current_feedforward + current_feedback\n",
    "            # simulate\n",
    "            next_state = self.f_(current_state, current_input, self.dt_, self.parameters_).flatten()\n",
    "            # store states and inputs\n",
    "            states[i+1,:] = next_state\n",
    "            inputs[i,:] = current_input.flatten()\n",
    "            \n",
    "            # update states\n",
    "            current_state = next_state\n",
    "\n",
    "        return (states, inputs)\n",
    "\n",
    "    def solve(self):\n",
    "        \"\"\"Solve all iLQR problem\n",
    "\n",
    "        Returns:\n",
    "            ndarray: Solved states\n",
    "            ndarray: Solved inputs\n",
    "            ndarray: Solved feedforward gains\n",
    "            ndarray: Solved feedback gains\n",
    "            double: final cost\n",
    "        \"\"\"\n",
    "        # rollout with the initial guess\n",
    "        [states, inputs] = self.rollout()\n",
    "\n",
    "        # compute initial cost\n",
    "        current_cost = self.compute_cost(states, inputs)\n",
    "\n",
    "        # learning parameters\n",
    "        learning_speed = 0.95 # this can be modified, 0.95 is very slow\n",
    "        low_learning_rate = 0.05 # if learning rate drops to this value stop the optimization\n",
    "        low_expected_reduction = 1e-3 # determines optimality\n",
    "        \n",
    "        armijo_threshold = 0.1 # determines if current line search solve is good (labelled as 'c' in (13))\n",
    "\n",
    "        # start solving\n",
    "        for i in range(0, self.n_iterations_):\n",
    "            print(\"Starting iteration: {}\".format(i))\n",
    "            # backward pass\n",
    "            (k_feedforward, K_feedback, expected_reduction) = self.backward_pass()\n",
    "\n",
    "            # check for convergence\n",
    "            if (np.abs(expected_reduction) < low_expected_reduction):\n",
    "                # there is no further reduction, end the optimization\n",
    "                print(\"Stopping optimization and accepting solution, abs_expected_reduction = {}\".format(np.abs(expected_reduction)))\n",
    "                break\n",
    "            \n",
    "            # start forward pass and line search with \\alpha = 1\n",
    "            learning_rate = 1\n",
    "            armijo_flag = False\n",
    "            # execute line search until the armijo condition is met (for now just check if the cost decreased)\n",
    "            # TODO: add real armijo condition\n",
    "            while (learning_rate > low_learning_rate and armijo_flag == False):\n",
    "                # compute forward pass\n",
    "                (new_states, new_inputs) = self.forward_pass(learning_rate)\n",
    "                new_cost = self.compute_cost(new_states, new_inputs)\n",
    "\n",
    "                # compute armijo condition\n",
    "                cost_difference = (current_cost - new_cost)\n",
    "                expected_cost_red = learning_rate * (self.expected_cost_reduction_grad_ + learning_rate*self.expected_cost_reduction_hess_)\n",
    "                armijo_flag = (cost_difference / expected_cost_red) > armijo_threshold # z (13)\n",
    "\n",
    "                print(\"Rate = {:.5f}, cost = {:.5f}, dcost = {:.5f}, expected cost red = {:.5f}, armijo = {}\".format(learning_rate, new_cost, cost_difference, expected_cost_red, armijo_flag))\n",
    "\n",
    "                if (armijo_flag):\n",
    "                    # accept new trajectory if armijo condition is met\n",
    "                    current_cost = new_cost\n",
    "                    self.states_ = new_states\n",
    "                    self.inputs_ = new_inputs\n",
    "                else:\n",
    "                    # no improvement, decrease learning rate and restart forward pass\n",
    "                    learning_rate = learning_speed*learning_rate\n",
    "\n",
    "            # if we exited while loop due to (learning_rate > low_learning_rate) being false\n",
    "            if (learning_rate < low_learning_rate):\n",
    "                print(\"Stopping optimization due to low learning rate\")\n",
    "                break\n",
    "\n",
    "        # return the current trajectory\n",
    "        states = self.states_\n",
    "        inputs = self.inputs_\n",
    "\n",
    "        return states, inputs, k_feedforward, K_feedback, current_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18536/2568082925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# ilqr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0milqr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0milqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_guess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Solve for swing up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18536/2587635017.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, init_state, target_state, initial_guess, dt, start_time, end_time, f_discrete, f_x, f_u, Q_k, R_k, Q_T, parameters, n_iterations)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# dynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_discrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "# import dynamics\n",
    "(f,f_x,f_u) = symbolic_dynamics_pendulum()\n",
    "\n",
    "# initialize timing\n",
    "dt = 0.005\n",
    "start_time = 0\n",
    "end_time = 5\n",
    "time_span = np.arange(start_time, end_time, dt)\n",
    "\n",
    "# set states (start and end states are at rest)\n",
    "n_states = 2 # position and velocity\n",
    "n_inputs = 1 # inputs to the system\n",
    "init_state = np.array([0,0])\n",
    "target_state = np.array([np.pi,0])\n",
    "\n",
    "# initial guess\n",
    "initial_guess = 0.1*np.ones((time_span.shape[0], n_inputs))\n",
    "\n",
    "# define weights\n",
    "Q_k = np.zeros((n_states, n_states)) # just find a valid trajectory first\n",
    "R_k = 0.001*np.eye(n_inputs)\n",
    "Q_T = 100*np.eye(n_states)\n",
    "\n",
    "# physical parameters\n",
    "mass = 1\n",
    "gravity = 9.8\n",
    "pendulum_length = 1\n",
    "parameters = np.array([mass, gravity, pendulum_length])\n",
    "\n",
    "# iterations\n",
    "n_iterations = 50\n",
    "\n",
    "# ilqr\n",
    "ilqr = ilqr(init_state, target_state, initial_guess, dt, start_time, end_time, f, f_x, f_u, Q_k, R_k, Q_T, parameters, n_iterations)\n",
    "\n",
    "# Solve for swing up\n",
    "(states,inputs,k_feedforward,K_feedback,current_cost) = ilqr.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Backtracking_line_search\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a056c220e358cd254f9e086c9fbc1600e1f6c115100e0ffe1e1fae2263f3989e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('hdrm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
