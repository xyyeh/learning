{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function _lambdifygenerated(_Dummy_23, _Dummy_24, dt, _Dummy_25)>,\n",
       " <function _lambdifygenerated(_Dummy_26, _Dummy_27, dt, _Dummy_28)>,\n",
       " <function _lambdifygenerated(_Dummy_29, _Dummy_30, dt, _Dummy_31)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "from sympy.matrices import Matrix\n",
    "\n",
    "def symbolic_dynamics_pendulum():\n",
    "    \"\"\"Symbolic dynamics for pendulum\n",
    "    \"\"\"\n",
    "    m, g, L, theta, theta_dot, u, dt = sp.symbols('m g L theta theta_dot u dt')\n",
    "\n",
    "    # inputs and states\n",
    "    inputs = Matrix([u])\n",
    "    states = Matrix([theta, theta_dot])\n",
    "\n",
    "    # dynamics for a pendulum of mass m and center of mass L\n",
    "    f = Matrix([theta_dot, m*g*L*sp.sin(theta)/(m*L*L)])\n",
    "\n",
    "    # discretize the system using euler integration\n",
    "    f_discrete = states + f*dt\n",
    "\n",
    "    # take the jacobian wrt states and inputs\n",
    "    A_discrete = f_discrete.jacobian(states) # df/dx\n",
    "    B_discrete = f_discrete.jacobian(inputs) # df/du\n",
    "\n",
    "    # define parameters\n",
    "    parameters = Matrix([m,g,L])\n",
    "\n",
    "    # create lambdas\n",
    "    f_discrete_func = sp.lambdify((states, inputs, dt, parameters), f_discrete)\n",
    "    A_discrete_func = sp.lambdify((states, inputs, dt, parameters), A_discrete)\n",
    "    B_discrete_func = sp.lambdify((states, inputs, dt, parameters), B_discrete)\n",
    "\n",
    "    return f_discrete_func, A_discrete_func, B_discrete_func\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1222818014.py, line 177)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_17197/1222818014.py\"\u001b[0;36m, line \u001b[0;32m177\u001b[0m\n\u001b[0;31m    inputs[i,:] current_input.flatten()\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ilqr:\n",
    "    def __init__(self, init_state, target_state, initial_guess, dt, start_time, end_time, f_discrete, A, B, Q_k, R_k, Q_T, parameters, n_iterations):\n",
    "        # states\n",
    "        self.init_state_ = init_state\n",
    "        self.target_state_ = target_state\n",
    "        self.inputs_ = initial_guess\n",
    "        self.n_states_ = np.shape(init_state)[0] # The dimensions of the state vector\n",
    "        self.n_inputs_ = np.shape(initial_guess)[1] # The dimension of the control vector\n",
    "\n",
    "        # timing\n",
    "        self.dt_ = dt\n",
    "        self.start_time_ = start_time\n",
    "        self.end_time_ = end_time\n",
    "        self.time_span_ = np.arange(start_time, end_time, dt).flatten()\n",
    "        self.n_timesteps_ = np.shape(self.time_span_)[0]\n",
    "\n",
    "        # dynamics\n",
    "        self.f_ = f_discrete\n",
    "        self.A_ = A\n",
    "        self.B_ = B\n",
    "\n",
    "        # weighting for loss function, i.e. L = x_T^T Q_T x_T + sum of (x_k^T Q_k x_k + u_k^T R_k u_k)\n",
    "        self.Q_k_ = Q_k # Weight for state vector\n",
    "        self.R_k_ = R_k # Weight for control vector\n",
    "        self.Q_T_ = Q_T # Weight for terminal state\n",
    "        self.parameters_ = parameters\n",
    "\n",
    "        # max iterations to run\n",
    "        self.n_iterations_ = n_iterations\n",
    "\n",
    "        # costs\n",
    "        self.expected_cost_reduction_ = 0\n",
    "        self.expected_cost_reduction_grad_ = 0\n",
    "        self.expected_cost_reduction_hess_ = 0\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\"rollout of the simulated system given an initial state\n",
    "        \"\"\"\n",
    "        # we store states and inputs as:\n",
    "        # state = [., x_1, x_2, ..., x_N]\n",
    "        # input =    [u_0, u_1, ..., u_{N-1}]\n",
    "        # the first value in state is understood as self.init_state_\n",
    "        states = np.zeros((self.n_timesteps_+1, self.n_states_)) # including initial state, x_0 to x_N\n",
    "        inputs = np.zeros((self.n_timesteps_, self.n_inputs_)) # u_0 to u_{N-1}\n",
    "        current_state = self.init_state_\n",
    "\n",
    "        for i in range(0, self.n_timesteps_): # 0 to N-1\n",
    "            current_input = self.inputs_[i,:] # u_k\n",
    "            next_state = self.f_(current_state, current_input, self.dt_, self.parameters_).flatten() # x_{k+1} = f(x_k, u_k) \n",
    "            # store both u_k and x_{k+1}\n",
    "            states[i+1,:] = next_state\n",
    "            inputs[i,:] = current_input\n",
    "            # update current state\n",
    "            current_state = next_state\n",
    "\n",
    "        # store trajectories\n",
    "        self.states_ = states\n",
    "        self.inputs_ = inputs\n",
    "\n",
    "        return states, inputs\n",
    "\n",
    "    def compute_cost(self, states, inputs):\n",
    "        \"\"\"Computes the cost\n",
    "\n",
    "        Args:\n",
    "            states (ndarray): State trajectory\n",
    "            inputs (ndarray): Input trajectory\n",
    "\n",
    "        Returns:\n",
    "            double: Total cost, i.e. terminal cost + running cost\n",
    "        \"\"\"\n",
    "        # accumulate cost to go\n",
    "        total_cost = 0\n",
    "        for i in range(0, self.n_timesteps_):\n",
    "            current_x = states[i,:]\n",
    "            current_u = inputs[i,:].flatten()\n",
    "            current_cost = current_u.T @ self.R_k_ @ current_u\n",
    "            total_cost = total_cost + current_cost\n",
    "        # add terminal cost\n",
    "        terminal_diff = (states[-1,:] - self.target_state_).flatten()\n",
    "        terminal_cost = terminal_diff.T @ self.Q_T_ @ terminal_diff\n",
    "        total_cost = total_cost + terminal_cost\n",
    "\n",
    "        return total_cost\n",
    "\n",
    "    def backward_pass(self):\n",
    "        \"\"\"[summary]\n",
    "\n",
    "        Returns:\n",
    "            ndarray: feedforward gain, k\n",
    "            ndarray: feedback gain, K\n",
    "            double: expected cost reduction\n",
    "        \"\"\"\n",
    "        # starting from the last state\n",
    "        V_xx = self.Q_T_ # since V_N = x_T^T Q_T x_T, V_xx(N) = Q_T_\n",
    "        terminal_diff = (self.states_[-1, :] - self.target_state_).flatten()\n",
    "        V_x = self.Q_T_ @ terminal_diff # V_x(N)\n",
    "\n",
    "        # initialize control modifications to be stored\n",
    "        k_trj = np.zeros((self.n_timesteps_, self.n_inputs_)) # (8b)\n",
    "        K_trj = np.zeros((self.n_timesteps_, self.n_inputs_, self.n_states_)) # (8b)\n",
    "\n",
    "        # initialize cost reduction\n",
    "        expected_cost_reduction = 0\n",
    "        expected_cost_reduction_grad = 0\n",
    "        expected_cost_reduction_hess = 0\n",
    "\n",
    "        # looping backwards from N-1 using the value V_{N}\n",
    "        for i in reversed(range(0, self.n_timesteps_)):\n",
    "            # current variables\n",
    "            current_x = self.states_[i,:]\n",
    "            current_u = self.inputs_[i,:]\n",
    "\n",
    "            # updates to partial derivatives of cost function\n",
    "            l_xx = self.Q_k_\n",
    "            l_uu = self.R_k_\n",
    "            l_x = self.Q_k_ @ np.zeros(self.n_states_).flatten()\n",
    "            l_u = self.R_k_ @ current_u.flatten()\n",
    "\n",
    "            # get jacobian of discrete dynamics\n",
    "            A_k = self.A_(current_x, current_u, self.dt_, self.parameters_) # V'_x\n",
    "            B_k = self.B_(current_x, current_u, self.dt_, self.parameters_) # V'_u\n",
    "    \n",
    "            # all the Q vector/matrices\n",
    "            Q_x = l_x + A_k.T @ V_x # (5a)\n",
    "            Q_u = l_u + B_k.T @ V_x # (5b)\n",
    "            Q_ux = B_k.T @ V_xx @ A_k # (5c)\n",
    "            Q_uu = l_uu + B_k.T @ V_xx @ B_k # (5d)\n",
    "            Q_xx = l_xx + A_k.T @ V_xx @ A_k # (5e)\n",
    "\n",
    "            # compute and store gains\n",
    "            Q_uu_inv = np.linalg.inv(Q_uu) # TODO: this can be singular, try using (9)\n",
    "            k = -Q_uu_inv @ Q_u # (6)\n",
    "            K = -Q_uu_inv @ Q_ux # (6)\n",
    "\n",
    "            k_trj[i,:] = k \n",
    "            K_trj[i,:,:] = K \n",
    "\n",
    "            # update the expected reduction (11a)\n",
    "            expected_cost_reduction_grad += (-Q_u.T @ k)\n",
    "            expected_cost_reduction_hess += (0.5 * k.T @ (Q_uu) @ (k))\n",
    "            expected_cost_reduction += (expected_cost_reduction_grad + expected_cost_reduction_hess)\n",
    "\n",
    "            # update hessian and gradient of value function for the next iteration\n",
    "            V_x = Q_x + K.T @ Q_uu @ k + K.T @ Q_u + Q_ux.T @ k # (11b)\n",
    "            V_xx = Q_xx + K.T @ Q_uu @ K + K.T @ Q_ux + Q_ux.T @ K # (11c)\n",
    "\n",
    "        # store values\n",
    "        self.expected_cost_reduction_grad_ = expected_cost_reduction_grad\n",
    "        self.expected_cost_reduction_hess_ = expected_cost_reduction_hess\n",
    "        self.expected_cost_reduction_ = expected_cost_reduction\n",
    "\n",
    "        # store gains\n",
    "        self.k_feedforward_ = k_trj\n",
    "        self.K_feedback_ = K_trj\n",
    "\n",
    "        return (k_trj, K_trj, expected_cost_reduction)\n",
    "\n",
    "    def forward_pass(self, learning_rate):\n",
    "        \"\"\"Forward pass of ilqr\n",
    "\n",
    "        Args:\n",
    "            learning_rate (double): learning rate (\\alpha)\n",
    "            \n",
    "        Returns:\n",
    "            ndarray: updated states, \\hat x (8a,b,c)\n",
    "            ndarray: updated inputs, \\hat u (12)\n",
    "        \"\"\"\n",
    "        # initialize before integration\n",
    "        states = np.zeros((self.n_timesteps_ + 1, self.n_states_)) # to store updated trajectory\n",
    "        inputs = np.zeros((self.n_timesteps_, self.n_inputs_)) # to store updated inputs\n",
    "        current_state = self.init_state_\n",
    "\n",
    "        # initialize and start integrating going forward for:\n",
    "        # state = [., x_1, x_2, ..., x_N]\n",
    "        # input =    [u_0, u_1, ..., u_{N-1}]\n",
    "        states[1,:] = current_state # (8a), assume that index 0 contains x_0\n",
    "        for i in range(0, self.n_timesteps_):\n",
    "            # use current gains\n",
    "            current_feedforward = learning_rate * self.k_feedforward_[i,:] # (12), \\hat represents the updated variables\n",
    "            current_feedback = self.K_feedback_[i,:,:] @ (current_state - self.states_[i,:]) # (12)\n",
    "            current_input = self.inputs_[i,:] + current_feedforward + current_feedback\n",
    "            # simulate\n",
    "            next_state = self.f_(current_state, current_input, self.dt_, self.parameters_).flatten()\n",
    "            # store states and inputs\n",
    "            states[i+1,:] = next_state\n",
    "            inputs[i,:] = current_input.flatten()\n",
    "            \n",
    "            # update states\n",
    "            current_state = next_state\n",
    "\n",
    "        return (states, inputs)\n",
    "\n",
    "    def solve(self):\n",
    "        # rollout with the initial guess\n",
    "        [states, inputs] = self.rollout()\n",
    "\n",
    "        # compute initial cost\n",
    "        current_cost = self.compute_cost(states, inputs)\n",
    "\n",
    "        # learning parameters\n",
    "        learning_speed = 0.95 # this can be modified, 0.95 is very slow\n",
    "        low_learning_rate = 0.05 # if learning rate drops to this value stop the optimization\n",
    "        low_expected_reduction = 1e-3 # determines optimality\n",
    "        armijo_threshold = 0.1 # determines if current line search solve is good (labelled as 'c' in (13))\n",
    "\n",
    "        # start solving\n",
    "        for i in range(0, self.n_iterations_):\n",
    "            # backward pass\n",
    "            (k_feedforward, K_feedback, expected_reduction) = self.backward_pass()\n",
    "            # print statistics\n",
    "            print(\"Iteration = {}, Cost = {}, Expected reduction = {}\".format(i, current_cost, expected_reduction))\n",
    "            if (abs(expected_reduction) < low_expected_reduction):\n",
    "                # there is no further reduction, end the optimization\n",
    "                print(\"Stopping optimization, accepting solution\")\n",
    "                break\n",
    "            \n",
    "            # start forward pass and line search with \\alpha = 1\n",
    "            learning_rate = 1\n",
    "            armijo_flag = 0\n",
    "            # execute linesearch until the armijo condition is met (for now just check if the cost decreased)\n",
    "            # TODO: add real armijo condition\n",
    "            while (learning_rate > 0.05 and armijo_flag == 0):\n",
    "                # compute forward pass\n",
    "                (new_states, new_inputs) = self.forward_pass(learning_rate)\n",
    "                new_cost = self.compute_cost(new_states, new_inputs)\n",
    "\n",
    "                # compute armijo condition\n",
    "                cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(a[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a056c220e358cd254f9e086c9fbc1600e1f6c115100e0ffe1e1fae2263f3989e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('hdrm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
