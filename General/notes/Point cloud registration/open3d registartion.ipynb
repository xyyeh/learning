{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Registration With Fphf & RANSAC\n",
    "1. This is adapted from [Open3D's example](http://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html) on global registration.\n",
    "2. The strategy is a two step process. The first step is to extract feature points from both source and target point clouds. The second step involves RANSAC where random voting is used to select surrounding feature points to check for correspondences. \n",
    "3. The randomness of RANSAC is desirable as it makes it robust against outliers.Once the correspondences are established, any kind of linear programming can be used to compute the transformation\n",
    "4. Due to the randomness of voting scheme, the returned result of the same data will be different due to redundant features being available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "\n",
    "    # Create line segments to represent coordinate axes\n",
    "    axis_length = 1.0\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(np.array([[0, 0, 0], [axis_length, 0, 0], [0, axis_length, 0], [0, 0, axis_length]]))\n",
    "    line_set.lines = o3d.utility.Vector2iVector(np.array([[0, 1], [0, 2], [0, 3]]))\n",
    "    line_set.colors = o3d.utility.Vector3dVector(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))  # RGB colors for X, Y, Z axes\n",
    "\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp, line_set],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "    \n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    start_time = time.perf_counter()\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(demo_icp_pcds.paths[0])\n",
    "    target = o3d.io.read_point_cloud(demo_icp_pcds.paths[1])\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    # draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    # Get the minimum and maximum bounds\n",
    "    min_bound = source.get_min_bound()\n",
    "    max_bound = source.get_max_bound()\n",
    "    print(\"Minimum bounds:\", min_bound)\n",
    "    print(\"Maximum bounds:\", max_bound)\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downsample and compute point features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      "Minimum bounds: [0.55859375 0.55078125 0.83203125]\n",
      "Maximum bounds: [2.5536561  3.9607718  2.42490005]\n",
      ":: Downsample with a voxel size 0.100.\n",
      "Time taken: 0.009619 seconds\n",
      ":: Estimate normal with search radius 0.200.\n",
      "Time taken: 0.001397 seconds\n",
      ":: Compute FPFH feature with search radius 0.500.\n",
      "Time taken: 0.020386 seconds\n",
      ":: Downsample with a voxel size 0.100.\n",
      "Time taken: 0.008279 seconds\n",
      ":: Estimate normal with search radius 0.200.\n",
      "Time taken: 0.030340 seconds\n",
      ":: Compute FPFH feature with search radius 0.500.\n",
      "Time taken: 0.013287 seconds\n",
      "# of points, source = PointCloud with 198835 points., target = PointCloud with 137833 points.\n",
      "# of point features, source = (33, 1301), target = (33, 914)\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.1  # decimation through voxelization. We use 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size) # compute fpfh of source and target pc\n",
    "\n",
    "print(f\"# of points, source = {source}, target = {target}\")\n",
    "print(f\"# of point features, source = {source_fpfh.data.shape}, target = {target_fpfh.data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RANSAC\n",
    "1. Random sample consensus is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates\n",
    "2. Psuedocode can be found from [here](https://en.wikipedia.org/wiki/Random_sample_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 0.100,\n",
      "   we use a liberal distance threshold 0.150.\n",
      "RegistrationResult with fitness=6.633359e-01, inlier_rmse=6.143286e-02, and correspondence_set size of 863\n",
      "Access transformation to get result.\n",
      "Time taken for RANSAC: 0.040384 seconds\n",
      "Transformation = \n",
      "[[-0.52010165  0.85191853  0.06106628  0.54398004]\n",
      " [-0.12086145 -0.14418748  0.98214178  0.6404427 ]\n",
      " [ 0.84550978  0.503433    0.17795625 -1.34411182]\n",
      " [ 0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(result_ransac)\n",
    "print(f\"Time taken for RANSAC: {elapsed_time:.6f} seconds\")\n",
    "print(f\"Transformation = \\n{result_ransac.transformation}\")\n",
    "\n",
    "# draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_ikflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
