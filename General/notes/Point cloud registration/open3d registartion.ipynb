{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D Registration With Fphf & RANSAC\n",
    "1. This is adapted from [Open3D's example](http://www.open3d.org/docs/release/tutorial/pipelines/global_registration.html) on global registration.\n",
    "2. The strategy is a two step process. The first step is to extract feature points from both source and target point clouds. The second step involves RANSAC where random voting is used to select surrounding feature points to check for correspondences. \n",
    "3. The randomness of RANSAC is desirable as it makes it robust against outliers.Once the correspondences are established, any kind of linear programming can be used to compute the transformation\n",
    "4. Due to the randomness of voting scheme, the returned result of the same data will be different due to redundant features being available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "\n",
    "    # Create line segments to represent coordinate axes\n",
    "    axis_length = 1.0\n",
    "    line_set = o3d.geometry.LineSet()\n",
    "    line_set.points = o3d.utility.Vector3dVector(np.array([[0, 0, 0], [axis_length, 0, 0], [0, axis_length, 0], [0, 0, axis_length]]))\n",
    "    line_set.lines = o3d.utility.Vector2iVector(np.array([[0, 1], [0, 2], [0, 3]]))\n",
    "    line_set.colors = o3d.utility.Vector3dVector(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))  # RGB colors for X, Y, Z axes\n",
    "\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp, line_set],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "    \n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    start_time = time.perf_counter()\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    end_time = time.perf_counter()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Time taken: {elapsed_time:.6f} seconds\")\n",
    "\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    # demo_icp_pcds = o3d.data.DemoICPPointClouds()\n",
    "    source = o3d.io.read_point_cloud(\"sill_part2_centered.pcd\")\n",
    "    target = o3d.io.read_point_cloud(\"sill_part2_centered.pcd\")\n",
    "    trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    source.transform(trans_init)\n",
    "    draw_registration_result(source, target, np.identity(4))\n",
    "\n",
    "    # Get the minimum and maximum bounds\n",
    "    min_bound = source.get_min_bound()\n",
    "    max_bound = source.get_max_bound()\n",
    "    print(\"Minimum bounds:\", min_bound)\n",
    "    print(\"Maximum bounds:\", max_bound)\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downsample and compute point features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Load two point clouds and disturb initial pose.\n",
      "Minimum bounds: [ -6.81040175 -35.73059214 -89.92822285]\n",
      "Maximum bounds: [14.58974473 25.38766551 29.6734404 ]\n",
      ":: Downsample with a voxel size 2.000.\n",
      "Time taken: 0.007886 seconds\n",
      ":: Estimate normal with search radius 4.000.\n",
      "Time taken: 0.015697 seconds\n",
      ":: Compute FPFH feature with search radius 10.000.\n",
      "Time taken: 0.043317 seconds\n",
      ":: Downsample with a voxel size 2.000.\n",
      "Time taken: 0.005506 seconds\n",
      ":: Estimate normal with search radius 4.000.\n",
      "Time taken: 0.014409 seconds\n",
      ":: Compute FPFH feature with search radius 10.000.\n",
      "Time taken: 0.034771 seconds\n",
      "# of points, source = PointCloud with 50000 points., target = PointCloud with 50000 points.\n",
      "# of point features, source = (33, 2942), target = (33, 2942)\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 2  # decimation through voxelization. We use 5cm for this dataset\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(\n",
    "    voxel_size\n",
    ")  # compute fpfh of source and target pc\n",
    "\n",
    "print(f\"# of points, source = {source}, target = {target}\")\n",
    "print(\n",
    "    f\"# of point features, source = {source_fpfh.data.shape}, target = {target_fpfh.data.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RANSAC\n",
    "1. Random sample consensus is an iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates\n",
    "2. Psuedocode can be found from [here](https://en.wikipedia.org/wiki/Random_sample_consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: RANSAC registration on downsampled point clouds.\n",
      "   Since the downsampling voxel size is 2.000,\n",
      "   we use a liberal distance threshold 3.000.\n",
      "RegistrationResult with fitness=1.000000e+00, inlier_rmse=1.080452e-14, and correspondence_set size of 2942\n",
      "Access transformation to get result.\n",
      "Time taken for RANSAC: 0.038716 seconds\n",
      "Transformation = \n",
      "[[-1.66533454e-16  1.00000000e+00  1.11022302e-16  7.10542736e-15]\n",
      " [-1.38777878e-17  8.32667268e-17  1.00000000e+00 -3.55271368e-15]\n",
      " [ 1.00000000e+00  5.55111512e-17 -1.31838984e-16 -8.88178420e-16]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size):\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "        distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        3, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999))\n",
    "    return result\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "end_time = time.perf_counter()\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(result_ransac)\n",
    "print(f\"Time taken for RANSAC: {elapsed_time:.6f} seconds\")\n",
    "print(f\"Transformation = \\n{result_ransac.transformation}\")\n",
    "\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_ikflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
