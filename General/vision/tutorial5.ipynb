{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization and Parallelization\n",
    "1. Vectorization and parallelization are done with two transformations, namely **`vmap`** and **`pmap`**\n",
    "2. To illustrate these functions we start with a typical dot product example using **`numpy`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70 70 70 70 70]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# What if we want to do dot products for a batch of vectors?\n",
    "array1 = np.stack([np.array([1, 2, 3, 4]) for i in range(5)])\n",
    "array2 = np.stack([np.array([5, 6, 7, 8]) for i in range(5)])\n",
    "\n",
    "# We can use `einsum`\n",
    "print(np.einsum('ij,ij-> i', array1, array2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is vmap\n",
    "1. In the above, we used functions that operate on batches of data such as **`einsum`** to get the dot products of the rows of both matrices\n",
    "2. The same can be done with another transformation, **`vmap`**. **`vmap`** takes a function as an input along the dimensions for hte inputs and the outputs where the functions is to be mapped over to create a vectorized function. The syntax looks like this **`vmap(function, in_axes, out_axes, ...)`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 µs ± 28.2 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "CPU times: user 23.7 ms, sys: 0 ns, total: 23.7 ms\n",
      "Wall time: 23.2 ms\n",
      "4.98 µs ± 478 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n",
      "[70 70 70 70 70]\n",
      "[70 70 70 70 70]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "from jax import make_jaxpr\n",
    "from jax.config import config\n",
    "from jax import grad, vmap, pmap, jit\n",
    "\n",
    "# A batch of vectors\n",
    "array1 = np.stack([np.array([1, 2, 3, 4]) for i in range(5)])\n",
    "array2 = jnp.stack([jnp.array([5, 6, 7, 8]) for i in range(5)])\n",
    "\n",
    "# Singular operation to be performed by vmap\n",
    "def dot_product(array1, array2):\n",
    "    \"\"\"Performs dot product on two jax arrays.\"\"\"\n",
    "    return jnp.dot(array1, array2)\n",
    "\n",
    "# Vmapped function\n",
    "func = vmap(dot_product, in_axes=(0,0), out_axes=(0))\n",
    "\n",
    "# Further transformation with jit\n",
    "jitted_func = jit(func)\n",
    "\n",
    "%timeit res1 = func(array1, array2)\n",
    "%time res2 = jitted_func(array1, array2)\n",
    "%timeit res3 = jitted_func(array1, array2)\n",
    "\n",
    "print(res1)\n",
    "print(res3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now, lets look at whats happening in the backend. Notice that now there is a **`dimension_numbers`** to specify the axes that the **`dot_general`** operation is executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:i32[5,4] b:i32[5,4]. let\n",
       "    c:i32[5] = dot_general[\n",
       "      dimension_numbers=(((1,), (1,)), ((0,), (0,)))\n",
       "      precision=None\n",
       "      preferred_element_type=None\n",
       "    ] a b\n",
       "  in (c,) }"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_jaxpr(vmap(dot_product, in_axes=(0,0), out_axes=(0)))(array1, array2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a056c220e358cd254f9e086c9fbc1600e1f6c115100e0ffe1e1fae2263f3989e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('hdrm': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
