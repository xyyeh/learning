{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 4\n",
    "#### Continuous Dynamic Programming\n",
    "1. Mapping discrete time to continous time dynamic programming equations\n",
    "<br>$s[n+1] = f_d(s[n],a[n]) \\Longleftrightarrow \\dot x = f_c(x,u)$\n",
    "<br>$\\min_{a[]} \\sum^{\\infty}_{n=0} g_d(s[n], a[n]) \\Longleftrightarrow \\min_{u()} \\int_{0}^{\\infty} g_c (x,u) dt$\n",
    "<br>$\\forall s, J^*(s) = \\min_{a} [g_d(s[n], a[n]) + J^*(f_d(s,a))]  \\Longleftrightarrow \\forall x, 0 = \\min_{u} [g_c(x,u) + \\frac{\\partial J^*}{\\partial x}{f_c(x,u)}]$\n",
    "\n",
    "2. The last equation is the HJB equation which happens to be a PDE. There is a lot of structure in the equation. With the optimal policy, $u*$, we have $-g_c(x,u*) = \\frac{\\partial J^*}{\\partial x}{f_c(x,u^*)}$. This tells us that the cost-to-go has to be changing over time at the same rate we are accruing cost.\n",
    "\n",
    "3. The HJB sufficiency theorem does have a problem, it requires that the cost-to-go $J*$ has to be differentiable. There are ways to get around it, for example in the bang-bang controller for the double integrator system, there is, in fact, no vector fields that goes across the \"ridge\" and thus, we can just look at the paths.\n",
    "\n",
    "#### Linear Quadratic Regulator\n",
    "1. Another barrier to using HJB is the minimization over $u$. This is addressed by the LQR problem:\n",
    "<br> $\\dot x = Ax + Bu$\n",
    "<br> $g(x,u) = x^T Q x + u^T R u, R \\in \\mathbb{S}_{++}, Q \\in \\mathbb{S}_{+}$\n",
    "\n",
    "2. Using a simple $J^*(x) = x^T S x,  S \\in \\mathbb{S}_{++} $ From the HJB euation, we have \n",
    "$$\\frac{\\partial J^*}{\\partial x} = 2 x^T S$$\n",
    "$$ 0 = \\min_{u} [g(x,u) + \\frac{\\partial J^*}{\\partial x}{f(x,u)}] = \\min_{u} [(x^T Q x + u^T R u) + 2 x^T S (Ax + Bu)]$$\n",
    "\n",
    "3. To minimize u, we can find $\\frac{\\partial []}{\\partial u} = u^T R + 2x^T S B = 0$ leading to $u* = R^{-1} B^T Sx = -Kx$. Substituting this to HJB, we have $0 = Q-SBR^{-1}B^TS + A^T S + SA$ which is the continuous algebraic ricatti equation i.e. **care**. This is often solved numerically, i.e. $[K,S]=lqr(A,B,Q,R)$\n",
    "\n",
    "4. Since $\\frac{\\partial J*}{\\partial x} = 2 x^T S$, the controller $u*$ means the following:\n",
    "<br> $-\\frac{\\partial J*}{\\partial x}^T$ \"go downhill\"\n",
    "<br> $-B^T \\frac{\\partial J*}{\\partial x}$ \"modulated by my control authority\"\n",
    "<br> $-R^{-1} B^T \\frac{\\partial J*}{\\partial x}$ \"taking into account preference on actuators\"\n",
    "\n",
    "#### Numerical Algorithms to Continuous actions\n",
    "1. To apply this continuous LQR in a digital control system, a numerical approach is needed. A good candidate for cost is $g(x,u) = g_1(x) + u^T R u$ (quadratic in u). In most systems, we have a control affine plant $f(x,u) = f_1(x) + f_2(x)u$.\n",
    "\n",
    "2. Applying this to the HJB equation, we have $\\min_{u} [(g_1(x) + u^T R u) + \\frac{\\partial J}{\\partial x}[f_1(x) + f_2(x)u]]$ and $u^* = -R^{-1} f^T_2(x) \\frac{\\partial J}{\\partial x}^T$\n",
    "\n",
    "3. Notice now that we will need to find $\\frac{\\partial J}{\\partial x}$. To numerically define this, we can use something as simple as a mesh, to more complicated linear function approximation (fitted value iteration) to a DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
