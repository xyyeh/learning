{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pytorch kinematics\n",
    "1. This is based on the repository from https://github.com/UM-ARM-Lab/pytorch_kinematics\n",
    "2. Simply install and run `pip-compile requirements.toml` and `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time for FK, [parallel] = 0.0017108179999922868, [sequential] = 0.4086778900000354\n",
      "Execution time for Jac, [parallel] = 0.005182711000088602\n",
      "Execution time for IK, [parallel] = 0.2590081399994233\n",
      "IK converged number: 882 / 4000\n",
      "IK took 30 iterations\n",
      "IK solved 371 / 400 goals\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import pytorch_kinematics as pk\n",
    "\n",
    "import os\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import time\n",
    "\n",
    "d = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.float32\n",
    "\n",
    "chain = pk.build_serial_chain_from_urdf(open(\"./urdf/kuka_iiwa.urdf\").read(), \"lbr_iiwa_link_7\")\n",
    "chain = chain.to(dtype=dtype, device=d)\n",
    "\n",
    "N = 400\n",
    "th_batch = torch.rand(N, len(chain.get_joint_parameter_names()), dtype=dtype, device=d)\n",
    "th = torch.rand(N, 7, dtype=dtype, device=d, requires_grad=True)\n",
    "\n",
    "########################### FK ###########################\n",
    "\n",
    "t1 = timer()\n",
    "# order of magnitudes faster when doing FK in parallel\n",
    "# elapsed 0.008678913116455078s for N=1000 when parallel\n",
    "# (N,4,4) transform matrix; only the one for the end effector is returned since end_only=True by default\n",
    "tg_batch = chain.forward_kinematics(th_batch)\n",
    "\n",
    "t2 = timer()\n",
    "\n",
    "# elapsed 8.44686508178711s for N=1000 when serial\n",
    "for i in range(N):\n",
    "    tg = chain.forward_kinematics(th_batch[i])\n",
    "t3 = timer()\n",
    "\n",
    "print(\"Execution time for FK, [parallel] = {}, [sequential] = {}\".format(t2-t1, t3-t2))\n",
    "\n",
    "########################### JACOBIAN ###########################\n",
    "\n",
    "t1 = timer()\n",
    "J = chain.jacobian(th)\n",
    "t2 = timer()\n",
    "\n",
    "print(\"Execution time for Jac, [parallel] = {}\".format(t2-t1))\n",
    "\n",
    "########################### INVERSE KINEMATICS ###########################\n",
    "# transformation from robot base frame to world frame\n",
    "pos = torch.tensor([0.0, 0.0, 0.0], device=d)\n",
    "rot = torch.tensor([0.0, 0.0, 0.0], device=d)\n",
    "rob_tf = pk.Transform3d(pos=pos, rot=rot, dtype=dtype, device=d)\n",
    "\n",
    "# world frame goals\n",
    "# generate random goal joint angles (so these are all achievable)\n",
    "# use the joint limits to generate random joint angles\n",
    "lim = torch.tensor(chain.get_joint_limits(), device=d)\n",
    "goal_q = torch.rand(N, 7, dtype=dtype, device=d) * (lim[1] - lim[0]) + lim[0]\n",
    "\n",
    "# get ee pose (in robot frame)\n",
    "goal_in_rob_frame_tf = chain.forward_kinematics(goal_q)\n",
    "\n",
    "# transform to world frame for visualization\n",
    "goal_tf = rob_tf.compose(goal_in_rob_frame_tf)\n",
    "goal = goal_tf.get_matrix()\n",
    "goal_pos = goal[..., :3, 3]\n",
    "goal_rot = pk.matrix_to_euler_angles(goal[..., :3, :3], \"XYZ\")\n",
    "\n",
    "ik = pk.PseudoInverseIK(chain, max_iterations=30, num_retries=10,\n",
    "                        joint_limits=lim.T,\n",
    "                        early_stopping_any_converged=True,\n",
    "                        early_stopping_no_improvement=\"all\",\n",
    "                        # line_search=pk.BacktrackingLineSearch(max_lr=0.2),\n",
    "                        debug=False,\n",
    "                        lr=0.2)\n",
    "\n",
    "t1 = timer()\n",
    "sol = ik.solve(goal_in_rob_frame_tf)\n",
    "t2 = timer()\n",
    "print(\"Execution time for IK, [parallel] = {}\".format(t2-t1))\n",
    "print(\"IK converged number: %d / %d\" % (sol.converged.sum(), sol.converged.numel()))\n",
    "print(\"IK took %d iterations\" % sol.iterations)\n",
    "print(\"IK solved %d / %d goals\" % (sol.converged_any.sum(), N))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_kine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
